{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb280d1-8aa0-43bc-aa76-6b270e70b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba memuat data dari: ..\\data\\raw\\histori_maintenance.csv\n",
      "Data CSV berhasil dimuat!\n",
      "Nama kolom terdeteksi: ['finding_description', 'action_taken', 'work_centre', 'materials_required', 'man_hours', 'Plant', 'Order']\n",
      "Kolom baru 'Plant' dan 'Order' berhasil ditemukan.\n",
      "\n",
      "--- 2. Pembersihan Data Awal ---\n",
      "Jumlah baris sebelum menangani NaN di kolom krusial: 22898\n",
      "Jumlah baris setelah menghapus NaN di ['finding_description', 'action_taken']: 22712\n",
      "Jumlah NaN di 'man_hours' setelah konversi ke numerik: 2\n",
      "Jumlah baris setelah menghapus NaN di 'man_hours': 22710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n",
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n",
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n",
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n",
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n",
      "C:\\Users\\583451\\AppData\\Local\\Temp\\ipykernel_11928\\3892883189.py:81: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].replace('nan', np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipe data setelah konversi dan pembersihan teks dasar:\n",
      "finding_description     object\n",
      "action_taken            object\n",
      "work_centre             object\n",
      "materials_required      object\n",
      "man_hours              float64\n",
      "Plant                   object\n",
      "Order                   object\n",
      "dtype: object\n",
      "\n",
      "Contoh data setelah pembersihan:\n",
      "                                 finding_description  \\\n",
      "0           a330 9m-xxr eng #1 phase array inspectio   \n",
      "1  during preliminary: panel 454jl 1 ea screw and...   \n",
      "2  during preliminary: panel 454jl 1 ea screw and...   \n",
      "3  during preliminary: rh eng scan light not ill ...   \n",
      "4  during preliminary: bleeding cap valve brake #...   \n",
      "\n",
      "                               action_taken work_centre  \\\n",
      "0  a330 9m-xxr eng #1 phase array inspectio        w808   \n",
      "1  complete screw and washer at panel 454jl    gah210a1   \n",
      "2  install screw and washer the pylon-to-wi    gah210a1   \n",
      "3  pse replace rh engine scan light ref amm    gah210e2   \n",
      "4  complete plug at brake #8 ref ipc fig. 3    gah210a1   \n",
      "\n",
      "           materials_required  man_hours Plant      Order  \n",
      "0                         NaN        9.0  wsnc  804422680  \n",
      "1  nas1169c10l:80205 (washer)        1.0  gah2  804693388  \n",
      "2  nas1169c10l:80205 (washer)        1.0  gah2  804693388  \n",
      "3                         NaN        2.0  gah2  804693389  \n",
      "4           7612:f0826 (plug)        1.0  gah2  804693390  \n",
      "\n",
      "--- 3. Agregasi Data ---\n",
      "Data berhasil diagregasi.\n",
      "Contoh data setelah agregasi:\n",
      "                                 finding_description  \\\n",
      "0  (customer finding) all iat escutcheon need tou...   \n",
      "1  (customer request)laminate inside waste box al...   \n",
      "2         .flexi hose corr. at bulk crg. under floor   \n",
      "3                                                  0   \n",
      "4  1 ea screw lg ctl lever found broken during re...   \n",
      "\n",
      "                                 rectification_steps  \\\n",
      "0  [obey all of the warnings, cautions, and, remo...   \n",
      "1  [general:, re-attach laminate inside waste box...   \n",
      "2  [read and fully understad the specified m, do ...   \n",
      "3         [perform ut phased array lp compressor fa]   \n",
      "4  [obey all of the warnings, cautions and n, ins...   \n",
      "\n",
      "               man_hours_per_step  \\\n",
      "0  [0.1, 2.0, 6.0, 3.0, 2.5, 0.1]   \n",
      "1                 [0.1, 1.0, 0.0]   \n",
      "2       [0.1, 3.0, 3.0, 1.0, 1.0]   \n",
      "3                           [1.0]   \n",
      "4                 [0.1, 1.0, 0.1]   \n",
      "\n",
      "                               work_centres_per_step materials_info  \\\n",
      "0  [gah310c1, gah310c1, w101, w103, gah330c1, gah...            NaN   \n",
      "1                                 [w401, w401, w401]            NaN   \n",
      "2  [gah310s1, gah330s1, gah330s1, gah330s1, gah33...            NaN   \n",
      "3                                             [w808]            NaN   \n",
      "4                     [gah330e1, gah330e1, gah330e1]            NaN   \n",
      "\n",
      "                        plants_per_step order_info  \n",
      "0  [gah3, gah3, wsss, wsss, gah3, gah3]  805460570  \n",
      "1                    [wscb, wscb, wscb]  805460279  \n",
      "2        [gah3, gah3, gah3, gah3, gah3]  805434778  \n",
      "3                                [wsnc]  804945473  \n",
      "4                    [gah3, gah3, gah3]  805501349  \n",
      "\n",
      "Kolom pada processed_df:\n",
      "['finding_description', 'rectification_steps', 'man_hours_per_step', 'work_centres_per_step', 'materials_info', 'plants_per_step', 'order_info']\n",
      "\n",
      "Panjang list (termasuk plant) untuk baris sampel pertama terlihat konsisten.\n",
      "\n",
      "--- 4. Menyimpan Data yang Sudah Diproses ---\n",
      "Data yang sudah diproses berhasil disimpan di: ..\\data\\processed\\processed_data_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "# --- Konfigurasi Nama Kolom dan Path File ---\n",
    "NAMA_FILE_CSV = 'histori_maintenance.csv' # GANTI JIKA PERLU (pastikan sudah ada kolom Plant & Order)\n",
    "NAMA_FILE_PROCESSED_CSV = 'processed_data_v2.csv' # Versi baru untuk file yang diproses\n",
    "\n",
    "# Definisikan nama-nama kolom aktual\n",
    "COLUMN_FINDING_DESC = 'finding_description'\n",
    "COLUMN_ACTION_TAKEN = 'action_taken'\n",
    "COLUMN_WORK_CENTRE = 'work_centre'\n",
    "COLUMN_MATERIALS = 'materials_required'\n",
    "COLUMN_MAN_HOURS = 'man_hours'\n",
    "COLUMN_PLANT = 'Plant' # Kolom baru\n",
    "COLUMN_ORDER = 'Order'   # Kolom baru\n",
    "\n",
    "# Path ke file data mentah dan folder data yang diproses\n",
    "PATH_RAW_DATA = os.path.join('..', 'data', 'raw', NAMA_FILE_CSV)\n",
    "PATH_PROCESSED_DATA_DIR = os.path.join('..', 'data', 'processed')\n",
    "PATH_PROCESSED_FILE = os.path.join(PATH_PROCESSED_DATA_DIR, NAMA_FILE_PROCESSED_CSV)\n",
    "\n",
    "# --- 1. Memuat Data Mentah ---\n",
    "print(f\"Mencoba memuat data dari: {PATH_RAW_DATA}\")\n",
    "try:\n",
    "    df = pd.read_csv(PATH_RAW_DATA)\n",
    "    print(\"Data CSV berhasil dimuat!\")\n",
    "    df.columns = df.columns.str.strip() # Membersihkan spasi nama kolom\n",
    "    print(f\"Nama kolom terdeteksi: {df.columns.tolist()}\")\n",
    "\n",
    "    # Validasi keberadaan kolom baru\n",
    "    required_new_cols = [COLUMN_PLANT, COLUMN_ORDER]\n",
    "    missing_cols = [col for col in required_new_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"PERINGATAN: Kolom baru berikut tidak ditemukan di CSV: {missing_cols}. Fungsi terkait mungkin tidak berjalan dengan benar.\")\n",
    "    else:\n",
    "        print(f\"Kolom baru '{COLUMN_PLANT}' dan '{COLUMN_ORDER}' berhasil ditemukan.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File tidak ditemukan di {PATH_RAW_DATA}\")\n",
    "    df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"Terjadi error saat memuat CSV: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n--- 2. Pembersihan Data Awal ---\")\n",
    "    \n",
    "    # a. Menangani Nilai Kosong (Missing Values)\n",
    "    critical_cols_for_dropna = [COLUMN_FINDING_DESC, COLUMN_ACTION_TAKEN]\n",
    "    # Jika Plant dan Order juga krusial per baris sebelum agregasi, tambahkan ke list di atas.\n",
    "    # Untuk Order, karena diagregasi dengan 'first', NaN mungkin tidak masalah jika setidaknya satu baris per grup punya nilai.\n",
    "    # Untuk Plant, karena diagregasi dengan 'list', NaN akan jadi bagian dari list.\n",
    "    \n",
    "    print(f\"Jumlah baris sebelum menangani NaN di kolom krusial: {len(df)}\")\n",
    "    df.dropna(subset=critical_cols_for_dropna, inplace=True)\n",
    "    print(f\"Jumlah baris setelah menghapus NaN di {critical_cols_for_dropna}: {len(df)}\")\n",
    "\n",
    "    # b. Memastikan Tipe Data yang Benar\n",
    "    try:\n",
    "        df[COLUMN_MAN_HOURS] = pd.to_numeric(df[COLUMN_MAN_HOURS], errors='coerce')\n",
    "        man_hours_nan_before_drop = df[COLUMN_MAN_HOURS].isnull().sum()\n",
    "        if man_hours_nan_before_drop > 0:\n",
    "            print(f\"Jumlah NaN di '{COLUMN_MAN_HOURS}' setelah konversi ke numerik: {man_hours_nan_before_drop}\")\n",
    "            df.dropna(subset=[COLUMN_MAN_HOURS], inplace=True)\n",
    "            print(f\"Jumlah baris setelah menghapus NaN di '{COLUMN_MAN_HOURS}': {len(df)}\")\n",
    "\n",
    "        # Kolom teks yang akan dibersihkan (lowercase, strip)\n",
    "        # Asumsi Plant dan Order adalah teks, sesuaikan jika berbeda\n",
    "        string_columns_to_clean = [COLUMN_FINDING_DESC, COLUMN_ACTION_TAKEN, COLUMN_WORK_CENTRE, COLUMN_MATERIALS]\n",
    "        if COLUMN_PLANT in df.columns: # Hanya proses jika kolom ada\n",
    "            string_columns_to_clean.append(COLUMN_PLANT)\n",
    "        if COLUMN_ORDER in df.columns: # Hanya proses jika kolom ada\n",
    "            string_columns_to_clean.append(COLUMN_ORDER)\n",
    "\n",
    "        for col in string_columns_to_clean:\n",
    "            if col in df.columns: # Pastikan kolom ada sebelum diakses\n",
    "                df[col] = df[col].astype(str).str.lower().str.strip()\n",
    "                # Ganti string 'nan' hasil astype(str) dengan nilai NaN numpy agar bisa di-handle oleh 'first' atau 'list' agg\n",
    "                df[col].replace('nan', np.nan, inplace=True) \n",
    "        \n",
    "        # Untuk kolom Plant dan Order, jika ada nilai NaN setelah .lower().strip() dan replace 'nan',\n",
    "        # bagaimana kita ingin menanganinya sebelum agregasi?\n",
    "        # Jika Plant harus selalu ada, kita bisa dropna:\n",
    "        # if COLUMN_PLANT in df.columns:\n",
    "        #     df.dropna(subset=[COLUMN_PLANT], inplace=True)\n",
    "        #     print(f\"Jumlah baris setelah menghapus NaN di '{COLUMN_PLANT}': {len(df)}\")\n",
    "        # Untuk Order, karena kita akan ambil 'first', nilai NaN akan diabaikan jika ada nilai non-NaN lain dalam grup.\n",
    "\n",
    "        print(\"Tipe data setelah konversi dan pembersihan teks dasar:\")\n",
    "        print(df.dtypes)\n",
    "        print(\"\\nContoh data setelah pembersihan:\")\n",
    "        print(df.head())\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"ERROR: Kolom tidak ditemukan saat konversi tipe data atau pembersihan teks: {e}\")\n",
    "        df = pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error saat pembersihan data: {e}\")\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n--- 3. Agregasi Data ---\")\n",
    "    \n",
    "    def aggregate_to_list(series):\n",
    "        # Mengabaikan NaN saat membuat list, kecuali semua nilai adalah NaN\n",
    "        cleaned_list = series.dropna().tolist()\n",
    "        return cleaned_list if cleaned_list else (np.nan if series.isnull().all() else [])\n",
    "\n",
    "\n",
    "    def aggregate_first_valid(series):\n",
    "        # Mengambil nilai non-NaN pertama\n",
    "        first_valid = series.dropna().iloc[0] if not series.dropna().empty else np.nan\n",
    "        return first_valid\n",
    "\n",
    "    agg_config = {\n",
    "        'rectification_steps': (COLUMN_ACTION_TAKEN, aggregate_to_list),\n",
    "        'man_hours_per_step': (COLUMN_MAN_HOURS, aggregate_to_list),\n",
    "        'work_centres_per_step': (COLUMN_WORK_CENTRE, aggregate_to_list),\n",
    "        'materials_info': (COLUMN_MATERIALS, aggregate_first_valid)\n",
    "    }\n",
    "\n",
    "    # Tambahkan agregasi untuk kolom baru jika ada\n",
    "    if COLUMN_PLANT in df.columns:\n",
    "        agg_config['plants_per_step'] = (COLUMN_PLANT, aggregate_to_list)\n",
    "    if COLUMN_ORDER in df.columns:\n",
    "        agg_config['order_info'] = (COLUMN_ORDER, aggregate_first_valid)\n",
    "    \n",
    "    try:\n",
    "        processed_df = df.groupby(COLUMN_FINDING_DESC).agg(**agg_config).reset_index()\n",
    "\n",
    "        print(\"Data berhasil diagregasi.\")\n",
    "        print(\"Contoh data setelah agregasi:\")\n",
    "        print(processed_df.head())\n",
    "        print(\"\\nKolom pada processed_df:\")\n",
    "        print(processed_df.columns.tolist())\n",
    "\n",
    "        # Verifikasi panjang list (jika kolom baru juga list)\n",
    "        if not processed_df.empty and COLUMN_PLANT in df.columns and 'plants_per_step' in processed_df.columns:\n",
    "            # Sesuaikan verifikasi untuk menyertakan plants_per_step jika perlu\n",
    "            try:\n",
    "                sample_row = processed_df.iloc[0]\n",
    "                if not (len(sample_row['rectification_steps']) == \\\n",
    "                        len(sample_row['man_hours_per_step']) == \\\n",
    "                        len(sample_row['work_centres_per_step']) == \\\n",
    "                        len(sample_row['plants_per_step'])): # Tambahkan plants_per_step\n",
    "                    print(\"\\nPERINGATAN: Ada ketidaksesuaian panjang list (termasuk plant) untuk baris sampel pertama!\")\n",
    "                else:\n",
    "                    print(\"\\nPanjang list (termasuk plant) untuk baris sampel pertama terlihat konsisten.\")\n",
    "            except TypeError: # Bisa terjadi jika salah satu list adalah float (NaN)\n",
    "                print(\"\\nPERINGATAN: Error saat verifikasi panjang list, mungkin karena ada nilai NaN yang diagregasi sebagai float.\")\n",
    "\n",
    "\n",
    "        print(\"\\n--- 4. Menyimpan Data yang Sudah Diproses ---\")\n",
    "        if not os.path.exists(PATH_PROCESSED_DATA_DIR):\n",
    "            os.makedirs(PATH_PROCESSED_DATA_DIR)\n",
    "            print(f\"Direktori '{PATH_PROCESSED_DATA_DIR}' berhasil dibuat.\")\n",
    "\n",
    "        processed_df.to_csv(PATH_PROCESSED_FILE, index=False)\n",
    "        print(f\"Data yang sudah diproses berhasil disimpan di: {PATH_PROCESSED_FILE}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"ERROR: Kolom tidak ditemukan saat agregasi: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error saat agregasi atau penyimpanan data: {e}\")\n",
    "else:\n",
    "    print(\"\\nTidak ada data untuk diproses lebih lanjut karena DataFrame kosong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbe574-f974-4510-8234-de3ee6085989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
